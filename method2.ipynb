{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac7d837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:加载BERT模型...\n",
      "d:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "INFO:__main__:数据加载完成\n",
      "INFO:__main__:处理完成: 参赛队号 202190000001, 初步结果: [202190000001, 0, 0, 1235.423165002405]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000007, 初步结果: [202190000007, 0, 0, 682.6336316566425]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000008, 初步结果: [202190000008, 0, 0, 1312.2167087201044]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000025, 初步结果: [202190000025, 0, 0, 1576.11830510994]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000026, 初步结果: [202190000026, 0, 0, 2430.3462656627053]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000037, 初步结果: [202190000037, 0, 0, 809.5950397184866]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000045, 初步结果: [202190000045, 1, 0, 603.3870976162247]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000046, 初步结果: [202190000046, 0, 0, 663.394928047697]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000047, 初步结果: [202190000047, 0, 0, 59.8211792089651]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000048, 初步结果: [202190000048, 0, 0, 2219.7261937469625]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000049, 初步结果: [202190000049, 0, 0, 599.1907479169435]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000050, 初步结果: [202190000050, 0, 0, 834.4535709458528]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000051, 初步结果: [202190000051, 0, 0, 38.50862688724989]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000063, 初步结果: [202190000063, 0, 1, 1]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000064, 初步结果: [202190000064, 0, 0, 327.00250496652063]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000065, 初步结果: [202190000065, 0, 1, 1]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000066, 初步结果: [202190000066, 0, 0, 1421.619284111537]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000077, 初步结果: [202190000077, 0, 0, 557.1443099938275]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000078, 初步结果: [202190000078, 0, 0, 573.632545293929]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000079, 初步结果: [202190000079, 0, 0, 990.1589160221557]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000080, 初步结果: [202190000080, 0, 0, 1428.8518993003793]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000081, 初步结果: [202190000081, 0, 1, 1]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000082, 初步结果: [202190000082, 0, 0, 425.96193965430956]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000086, 初步结果: [202190000086, 1, 0, 757.6527974729111]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000099, 初步结果: [202190000099, 0, 0, 1104.104529048213]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000100, 初步结果: [202190000100, 1, 0, 610.7507173399105]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000142, 初步结果: [202190000142, 0, 0, 815.7325279524488]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000143, 初步结果: [202190000143, 0, 0, 894.409739211081]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000145, 初步结果: [202190000145, 0, 0, 640.1617496564508]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000146, 初步结果: [202190000146, 0, 0, 176.48502978856055]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000147, 初步结果: [202190000147, 0, 0, 354.2878174792459]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000152, 初步结果: [202190000152, 0, 0, 985.6236847327592]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000153, 初步结果: [202190000153, 0, 0, 381.38210541401975]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000154, 初步结果: [202190000154, 0, 1, 1]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000188, 初步结果: [202190000188, 0, 0, 507.5382106871741]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000189, 初步结果: [202190000189, 0, 0, 1]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000204, 初步结果: [202190000204, 0, 1, 1]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000205, 初步结果: [202190000205, 1, 0, 491.1218244206168]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000206, 初步结果: [202190000206, 1, 0, 1119.5700366016904]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000212, 初步结果: [202190000212, 0, 0, 1]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000213, 初步结果: [202190000213, 0, 0, 317.2946766824549]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000218, 初步结果: [202190000218, 0, 0, 196.20782654912165]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000230, 初步结果: [202190000230, 0, 1, 1]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000231, 初步结果: [202190000231, 0, 0, 1]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000232, 初步结果: [202190000232, 0, 1, 1]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000240, 初步结果: [202190000240, 0, 0, 775.251561972008]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000241, 初步结果: [202190000241, 0, 0, 1]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000242, 初步结果: [202190000242, 0, 0, 877.2882910421644]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000255, 初步结果: [202190000255, 0, 0, 217.21870767480388]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000256, 初步结果: [202190000256, 0, 0, 882.4565421749999]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000257, 初步结果: [202190000257, 0, 0, 487.0771163578178]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000258, 初步结果: [202190000258, 0, 0, 539.238293767339]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000259, 初步结果: [202190000259, 0, 0, 352.9029152465426]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000269, 初步结果: [202190000269, 0, 0, 1121.5532240151554]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000270, 初步结果: [202190000270, 0, 0, 698.055497732225]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000271, 初步结果: [202190000271, 0, 0, 1190.035766290527]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000272, 初步结果: [202190000272, 0, 0, 514.4517307490543]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000273, 初步结果: [202190000273, 1, 0, 608.5919450014834]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000278, 初步结果: [202190000278, 0, 0, 275.83799827347804]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000279, 初步结果: [202190000279, 0, 0, 571.896935770568]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000292, 初步结果: [202190000292, 0, 1, 1]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000293, 初步结果: [202190000293, 0, 0, 871.597381473922]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000297, 初步结果: [202190000297, 0, 0, 414.65074686554806]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000298, 初步结果: [202190000298, 0, 0, 587.39765520998]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000299, 初步结果: [202190000299, 0, 0, 480.8967649086525]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000300, 初步结果: [202190000300, 0, 0, 514.2000236582729]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000301, 初步结果: [202190000301, 0, 0, 375.81415338593155]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000305, 初步结果: [202190000305, 0, 0, 132.95517808567286]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000306, 初步结果: [202190000306, 0, 0, 553.5902305151003]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000311, 初步结果: [202190000311, 0, 0, 1]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000312, 初步结果: [202190000312, 0, 0, 368.92646561088503]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000313, 初步结果: [202190000313, 0, 1, 1]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000314, 初步结果: [202190000314, 0, 0, 28.030653797633406]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000315, 初步结果: [202190000315, 0, 0, 378.1349164769937]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000316, 初步结果: [202190000316, 0, 0, 615.136456880201]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000317, 初步结果: [202190000317, 0, 0, 1]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000318, 初步结果: [202190000318, 0, 0, 883.3247123331054]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000319, 初步结果: [202190000319, 0, 0, 1142.3593673212185]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000320, 初步结果: [202190000320, 0, 1, 1]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000321, 初步结果: [202190000321, 0, 0, 899.3197396045784]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000322, 初步结果: [202190000322, 0, 0, 1250.5048476549985]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000323, 初步结果: [202190000323, 0, 0, 172.24115799443666]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000324, 初步结果: [202190000324, 0, 0, 788.2444681097443]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000325, 初步结果: [202190000325, 0, 0, 215.08532459882164]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000336, 初步结果: [202190000336, 0, 0, 533.6332762844128]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000349, 初步结果: [202190000349, 0, 0, 1404.5474237172732]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000350, 初步结果: [202190000350, 0, 0, 245.44384226698787]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000351, 初步结果: [202190000351, 0, 0, 195.86478900356343]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000361, 初步结果: [202190000361, 0, 0, 2727.551132079363]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000368, 初步结果: [202190000368, 0, 0, 495.2725975912348]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000369, 初步结果: [202190000369, 0, 0, 218.4072202563506]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000370, 初步结果: [202190000370, 0, 0, 603.0537014933117]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000371, 初步结果: [202190000371, 0, 0, 518.6876837686934]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000372, 初步结果: [202190000372, 0, 1, 1]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000379, 初步结果: [202190000379, 0, 0, 373.24060795599195]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000380, 初步结果: [202190000380, 0, 0, 782.9222988906306]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000381, 初步结果: [202190000381, 0, 0, 229.41670057791393]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000382, 初步结果: [202190000382, 0, 0, 1]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000388, 初步结果: [202190000388, 0, 0, 1025.8021549479133]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000389, 初步结果: [202190000389, 0, 0, 454.7036592879926]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000395, 初步结果: [202190000395, 0, 1, 1]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000396, 初步结果: [202190000396, 0, 0, 1]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000399, 初步结果: [202190000399, 0, 0, 833.0954732058104]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000400, 初步结果: [202190000400, 0, 0, 617.5669134431494]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000401, 初步结果: [202190000401, 0, 0, 998.6692116190154]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000402, 初步结果: [202190000402, 0, 0, 239.75678934489173]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000403, 初步结果: [202190000403, 0, 0, 672.0109907269609]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000404, 初步结果: [202190000404, 0, 0, 417.2394619747298]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000414, 初步结果: [202190000414, 1, 0, 713.0685132815786]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000415, 初步结果: [202190000415, 0, 0, 527.6001906545248]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000419, 初步结果: [202190000419, 0, 0, 1063.1133047638634]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000420, 初步结果: [202190000420, 0, 0, 1119.1646577987956]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000421, 初步结果: [202190000421, 0, 0, 226.7701836207336]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000422, 初步结果: [202190000422, 0, 0, 1210.9301296788992]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000423, 初步结果: [202190000423, 0, 0, 904.3615747366175]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000424, 初步结果: [202190000424, 0, 0, 503.43254833947907]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000432, 初步结果: [202190000432, 0, 0, 471.7303706153006]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000433, 初步结果: [202190000433, 0, 0, 1320.4781220803063]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000434, 初步结果: [202190000434, 0, 0, 612.713253135674]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000435, 初步结果: [202190000435, 0, 0, 641.2144126850233]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000436, 初步结果: [202190000436, 0, 0, 1]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000437, 初步结果: [202190000437, 0, 0, 1613.9070134336798]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000438, 初步结果: [202190000438, 0, 1, 1]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000439, 初步结果: [202190000439, 0, 0, 415.167364880986]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000440, 初步结果: [202190000440, 0, 0, 690.6540100247036]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000445, 初步结果: [202190000445, 0, 1, 1]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000449, 初步结果: [202190000449, 0, 0, 1]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000450, 初步结果: [202190000450, 0, 0, 1215.4575014575148]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000451, 初步结果: [202190000451, 0, 0, 822.2511583309046]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000463, 初步结果: [202190000463, 0, 0, 523.9498768072121]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000464, 初步结果: [202190000464, 0, 0, 574.8575629514897]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000471, 初步结果: [202190000471, 0, 0, 1284.188279800339]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000472, 初步结果: [202190000472, 1, 0, 1112.4601734123412]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000473, 初步结果: [202190000473, 0, 0, 794.1093987952365]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000501, 初步结果: [202190000501, 0, 0, 662.9681618904165]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000502, 初步结果: [202190000502, 0, 0, 1248.3624445318005]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000503, 初步结果: [202190000503, 0, 0, 559.6200359904817]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000535, 初步结果: [202190000535, 0, 1, 1]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000536, 初步结果: [202190000536, 0, 0, 782.9295502686853]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000537, 初步结果: [202190000537, 1, 0, 1062.9162941460395]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000538, 初步结果: [202190000538, 0, 0, 872.569798118763]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000539, 初步结果: [202190000539, 0, 0, 1221.818190331538]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000545, 初步结果: [202190000545, 0, 0, 3207.981341008263]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000546, 初步结果: [202190000546, 0, 0, 405.7667851748806]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000549, 初步结果: [202190000549, 0, 1, 1]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000550, 初步结果: [202190000550, 0, 0, 1078.7142013559962]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000551, 初步结果: [202190000551, 0, 0, 454.53550281973446]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000553, 初步结果: [202190000553, 0, 0, 271.16589096231314]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000554, 初步结果: [202190000554, 1, 0, 19.590017221990436]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000555, 初步结果: [202190000555, 0, 0, 734.2742507670008]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000556, 初步结果: [202190000556, 0, 0, 832.4731681816587]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000557, 初步结果: [202190000557, 0, 0, 846.2494241991769]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000561, 初步结果: [202190000561, 0, 1, 1]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000562, 初步结果: [202190000562, 0, 0, 278.5916343426194]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000567, 初步结果: [202190000567, 0, 0, 121.56497522637396]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000568, 初步结果: [202190000568, 0, 0, 290.1724761718187]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000575, 初步结果: [202190000575, 0, 0, 545.7255940753481]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000576, 初步结果: [202190000576, 0, 0, 409.1711368779485]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000577, 初步结果: [202190000577, 0, 0, 510.0998402534799]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000578, 初步结果: [202190000578, 0, 0, 810.6317513366938]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000593, 初步结果: [202190000593, 0, 0, 265.53513143380405]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000595, 初步结果: [202190000595, 0, 0, 1523.2347636923796]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000599, 初步结果: [202190000599, 0, 0, 136.2426148907159]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000602, 初步结果: [202190000602, 0, 0, 877.3410317312791]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000615, 初步结果: [202190000615, 0, 1, 1]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000616, 初步结果: [202190000616, 0, 0, 256.6317627571998]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000617, 初步结果: [202190000617, 0, 1, 1]\n",
      "INFO:__main__:处理完成: 参赛队号 202190000618, 初步结果: [202190000618, 0, 0, 588.2916763427824]\n",
      "INFO:__main__:结果已保存\n",
      "INFO:__main__:处理完成，以下是符合筛选条件的前5篇论文:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "归一化后的实质性内容得分: [0.38133121825729677, 0.20795553214819182, 0.4054165753917233, 0.4881860881617078, 0.7561042556024453, 0.2477754272516182, 0.18310082455655555, 0.20192154771678922, 0.012618012628136067, 0.6900458422751792, 0.18178469072192388, 0.2555720019825537, 0.005933590875160599, 1.0, 0.09641617246012082, 1.0, 0.4397293570679433, 0.16859733896574577, 0.17376867260258472, 0.30440708189093835, 0.4419977784925298, 1.0, 0.12745359059305966, 0.2314843773236899, 0.3401447318387323, 0.1854103339535832, 0.24970037548120808, 0.27437652193527684, 0.19463474505303827, 0.049208204587714924, 0.10497387750378011, 0.3029846619842091, 0.11347167002148113, 1.0, 0.15303899174011562, 1.0, 1.0, 0.14789019267518072, 0.3449952994080581, 1.0, 0.09337143067712741, 0.055394018924061796, 1.0, 1.0, 1.0, 0.23700401488128994, 1.0, 0.26900658881534073, 0.06198382519060608, 0.2706275476651152, 0.1466216193878855, 0.16298133565620695, 0.10453951983181821, 0.3456173019203187, 0.21279241210095395, 0.36709601495170635, 0.1552073328751273, 0.18473326137396537, 0.08036904979003281, 0.17322431987197326, 1.0, 0.2672217045303452, 0.12390597311449708, 0.17808593121929203, 0.1446832276343206, 0.1551283880201142, 0.11172534986731757, 0.0355555982159239, 0.1674826453419698, 1.0, 0.10956511071359058, 1.0, 0.0026473025794147374, 0.1124532288681631, 0.1867858675988957, 1.0, 0.2708998386325472, 0.3521428946701307, 1.0, 0.27591648359458365, 0.38606140383397924, 0.04787716602840652, 0.24107908121358287, 0.06131471564308391, 0.16122339037480088, 0.43437497654792906, 0.07083629395176999, 0.05528642938729475, 0.84931893229518, 0.14919203198820735, 0.062356587646920675, 0.1829962589342539, 0.1565358878075278, 1.0, 0.1109181887730252, 0.2394098478357949, 0.06580957669485517, 1.0, 0.31558614848161975, 0.1364680799436177, 1.0, 1.0, 0.25514605121236106, 0.18754815061755045, 0.3070762321716365, 0.0690526192567383, 0.20462387055118716, 0.12471789199342176, 0.2175010610793125, 0.15933118674694643, 0.32728833495339904, 0.3448681572972794, 0.06497952897221944, 0.3736492768529337, 0.2774977936095826, 0.1517513008857761, 0.14180830001017106, 0.4080076667984053, 0.1860258593381627, 0.19496489995614547, 1.0, 0.5000380550272007, 1.0, 0.12406800404576446, 0.21047102587326466, 1.0, 1.0, 0.375069231720092, 0.251744864289663, 0.15818631038874023, 0.17415288443016744, 0.39662580096241606, 0.3427653776489855, 0.242918545096745, 0.20178769772350366, 0.3853894652588066, 0.16937382018942262, 1.0, 0.2394121221419632, 0.32722654497914017, 0.26752669113521593, 0.3770641841045658, 1.0, 0.12111962702692913, 1.0, 0.3321813656412402, 0.13641533972098455, 0.07890370039069476, 0.0, 0.22415198166337683, 0.25495087284152895, 0.259271627296838, 1.0, 0.08123269411392696, 0.03198320019365954, 0.08486488372089367, 0.16501599817068946, 0.1221873603624424, 0.1538424155693035, 0.2481005791896733, 0.07713768143107018, 0.47159981124424327, 0.03658666262151234, 0.26902313028837804, 1.0, 0.07434524857937387, 1.0, 0.17836633002922878]\n",
      "            参赛队号  是否包含参赛队信息  是否与赛题无关  是否无实质内容\n",
      "6   202190000045          1        0        0\n",
      "8   202190000047          0        0        1\n",
      "12  202190000051          0        0        1\n",
      "13  202190000063          0        1        1\n",
      "15  202190000065          0        1        1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import jieba \n",
    "from collections import Counter\n",
    "import math\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# 论文评估\n",
    "class PaperEvaluator:\n",
    "    def __init__(self):\n",
    "        # 加载停用词\n",
    "        self.stopwords = {'的', '了', '和', '是', '在', '我', '有', '这', '他', '它', '们', '与', '以', '为', '上', '下', '从', '但', '所', '如', '对', '之', '也', '而', '或', '自', '其', '那', '并', '等', '被', '一', '二', '三', '不', '能', '会', '就', '没', '到', '很', '可', '个', '又', '因', '此', '只', '每', '于', '你', '我们', '你们', '他们', '她们', '这些', '那些', '什么', '怎么', '这样', '那样', '这个', '那个', '如何', '为什么', '可以', '不能', '应该', '如此', '一些'}\n",
    "        \n",
    "        # 创新性相关的词汇\n",
    "        self.novelty_terms = [\n",
    "            \"新颖\", \"新的\", \"创新\", \"首次\", \"开创性\", \"原创的\", \"进步\", \"贡献\", \n",
    "            \"提出\", \"突破\", \"前所未有的\", \"独特的\", \"革命性的\", \"改进\", \"增强的\", \n",
    "            \"优于\", \"优越的\", \"超过\", \"提升\"\n",
    "        ]\n",
    "        \n",
    "        # 学术术语识别的词汇长度阈值\n",
    "        self.term_length_threshold = 2\n",
    "    \n",
    "    # 提取标题\n",
    "    def _extract_title(self, text):\n",
    "        lines = text.strip().split('\\n')\n",
    "        for line in lines[:7]:\n",
    "            line = line.strip()\n",
    "            # 标题通常不会太短或太长\n",
    "            if line and len(line) > 10 and len(line) < 200:\n",
    "                return line\n",
    "                \n",
    "        # 尝试获取第一个句子\n",
    "        first_part = text.split('\\n\\n')[0] if '\\n\\n' in text else text[:500]\n",
    "        sentences = re.split(r'[。！？!?]+', first_part)\n",
    "        if sentences and len(sentences[0]) < 200:\n",
    "            return sentences[0]\n",
    "            \n",
    "        return \"\" \n",
    "\n",
    "    # 提取摘要内容\n",
    "    def _extract_abstract(self, text):\n",
    "        abstract_content = []\n",
    "        is_in_abstract = False\n",
    "        lines = text.strip().split('\\n')\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip() \n",
    "            if line.startswith('#'):\n",
    "                if '摘要' in line:\n",
    "                    is_in_abstract = True\n",
    "                elif is_in_abstract:  \n",
    "                    break\n",
    "            elif is_in_abstract:  # 非标题行且在摘要区域时收集内容\n",
    "                abstract_content.append(line) \n",
    "                \n",
    "        return ''.join(abstract_content).strip()\n",
    "    \n",
    "    # 提取文章各个章节标题\n",
    "    def _extract_sections_title(self, text):\n",
    "        titles = []\n",
    "        lines = text.strip().split('\\n') \n",
    "        \n",
    "        for line in lines:\n",
    "            if line.strip().startswith('#'):\n",
    "                parts = line.strip().split(' ', 1)\n",
    "                if len(parts) > 1:\n",
    "                    level = parts[0].count('#')\n",
    "                    title_text = parts[1].strip()\n",
    "                    titles.append({\n",
    "                        'level': level,\n",
    "                        'text': title_text\n",
    "                    })\n",
    "        \n",
    "        return [title['text'] for title in titles]\n",
    "    \n",
    "    # 计算有效词数\n",
    "    def _count_words(self, text):\n",
    "        # 使用jieba分词\n",
    "        words = list(jieba.cut(text))\n",
    "        # 过滤停用词\n",
    "        filtered_words = []\n",
    "        for word in words:\n",
    "            if word not in self.stopwords and word.strip():\n",
    "                filtered_words.append(word)\n",
    "        return len(filtered_words)\n",
    "    \n",
    "    # 计算句子数\n",
    "    def _count_sentences(self, text):\n",
    "        sentences = re.split(r'[。！？!?]+', text)\n",
    "        count = 0\n",
    "        for s in sentences:\n",
    "            if s.strip():\n",
    "                count += 1\n",
    "        return count\n",
    "    \n",
    "    # 计算词汇多样性\n",
    "    def _calculate_lexical_diversity(self, text):\n",
    "        # 使用jieba分词\n",
    "        words = list(jieba.cut(text))\n",
    "        \n",
    "        # 过滤停用词\n",
    "        meaningful_words = []\n",
    "        for word in words:\n",
    "            if word not in self.stopwords and word.strip():\n",
    "                meaningful_words.append(word)\n",
    "                \n",
    "        if not meaningful_words:\n",
    "            return 0\n",
    "        \n",
    "        # 计算不同的词的数量\n",
    "        word_types = len(set(meaningful_words))\n",
    "        word_tokens = len(meaningful_words)\n",
    "        \n",
    "        if word_tokens < 100:\n",
    "            # 简单类型-符号比(TTR)\n",
    "            diversity = word_types / max(1, word_tokens)\n",
    "        else:\n",
    "            # 使用ROOT TTR: 类型数 / 词数的平方根\n",
    "            diversity = word_types / math.sqrt(word_tokens)\n",
    "            \n",
    "        return diversity\n",
    "    \n",
    "    # 估计专业术语密度\n",
    "    def _technical_term_density(self, text):\n",
    "        # 分词\n",
    "        all_words = list(jieba.cut(text))\n",
    "        \n",
    "        # 过滤空词\n",
    "        filtered_words = []\n",
    "        for w in all_words:\n",
    "            if w.strip():\n",
    "                filtered_words.append(w)\n",
    "        all_words = filtered_words\n",
    "        \n",
    "        if not all_words:\n",
    "            return 0\n",
    "            \n",
    "        # 识别潜在术语 (长词、非停用词、不含数字)\n",
    "        potential_terms = []\n",
    "        for w in all_words:\n",
    "            has_digit = False\n",
    "            for c in w:\n",
    "                if c.isdigit():\n",
    "                    has_digit = True\n",
    "                    break\n",
    "            \n",
    "            if len(w) > self.term_length_threshold and w not in self.stopwords and not has_digit:\n",
    "                potential_terms.append(w)\n",
    "        \n",
    "        # 计算词频\n",
    "        word_freq = Counter(all_words)\n",
    "        \n",
    "        # 重复出现的词汇\n",
    "        repeated_terms = []\n",
    "        for w in potential_terms:\n",
    "            if word_freq[w] > 3:\n",
    "                repeated_terms.append(w)\n",
    "\n",
    "        # 计算术语密度\n",
    "        term_density = len(potential_terms) / len(all_words) if all_words else 0\n",
    "        \n",
    "        # 计算术语重复率\n",
    "        term_repetition = len(repeated_terms) / max(1, len(potential_terms))\n",
    "\n",
    "        # 加权计算最终得分\n",
    "        final_score = 0.7 * term_density + 0.3 * term_repetition\n",
    "        return final_score\n",
    "    \n",
    "    # 计算引用密度\n",
    "    def _citation_density(self, text):\n",
    "        # 不同引用格式的正则表达式\n",
    "        patterns = [\n",
    "            r'\\[\\d+(,\\s*\\d+)*\\]',  # [1] 或 [1,2,3]\n",
    "            r'【\\d+】',  # 中文引用格式【1】\n",
    "        ]\n",
    "        \n",
    "        # 找出所有引用\n",
    "        all_citations = []\n",
    "        for pattern in patterns:\n",
    "            matches = re.findall(pattern, text)\n",
    "            all_citations.extend(matches)\n",
    "        # 计算引用数\n",
    "        citation_count = len(all_citations)\n",
    "        # 获取词数\n",
    "        word_count = self._count_words(text)\n",
    "        # 计算每千字引用数\n",
    "        if word_count == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return (citation_count / word_count) * 1000\n",
    "    \n",
    "    # 检查论文结构完整性\n",
    "    def _check_structure(self, sections):\n",
    "        # 核心章节及权重\n",
    "        core_sections = {\n",
    "            '摘要': 0.15,\n",
    "            '目录': 0.2,\n",
    "            '问题背景': 0.25,\n",
    "            '分析': 0.2,\n",
    "            '数据处理': 0.1,\n",
    "            '模型': 0.05,\n",
    "            '参考文献': 0.05\n",
    "        }\n",
    "        \n",
    "        # 计算得分\n",
    "        total_score = 0\n",
    "        for section, weight in core_sections.items():\n",
    "            found = False\n",
    "            for doc_section in sections:\n",
    "                if section in doc_section:\n",
    "                    found = True\n",
    "                    break\n",
    "            \n",
    "            if found:\n",
    "                total_score += weight\n",
    "                \n",
    "        return total_score\n",
    "    \n",
    "    # 评估论点一致性\n",
    "    def _evaluate_argument_consistency(self, text, abstract):\n",
    "        if not abstract or not text or len(abstract) < 20:\n",
    "            return 0.5 \n",
    "        \n",
    "        # 从摘要中提取关键词，排除停用词\n",
    "        abstract_words = []\n",
    "        for w in jieba.cut(abstract):\n",
    "            if w not in self.stopwords and len(w) > 1:\n",
    "                abstract_words.append(w)\n",
    "        \n",
    "        # 获取摘要中的高频词\n",
    "        if not abstract_words:\n",
    "            return 0.5\n",
    "        N = min(10, len(abstract_words) // 2)\n",
    "        if N == 0:\n",
    "            return 0.5\n",
    "            \n",
    "        # 计算词频\n",
    "        abstract_freq = Counter(abstract_words)\n",
    "        top_keywords = []\n",
    "        for word, _ in abstract_freq.most_common(N):\n",
    "            top_keywords.append(word)\n",
    "        \n",
    "        if not top_keywords:\n",
    "            return 0.5\n",
    "            \n",
    "        # 检查正文中是否包含这些关键词\n",
    "        matches = 0\n",
    "        for keyword in top_keywords:\n",
    "            if keyword in text:\n",
    "                matches += 1\n",
    "                \n",
    "        return matches / max(1, len(top_keywords))\n",
    "    \n",
    "    # 评估论文创新性\n",
    "    def _assess_novelty(self, text, title):\n",
    "        combined_text = title + \" \" + text\n",
    "        \n",
    "        # 计算创新性术语出现次数\n",
    "        novelty_score = 0\n",
    "        for term in self.novelty_terms:\n",
    "            if term in combined_text:\n",
    "                # 标题中出现的创新性术语权重更高\n",
    "                if term in title:\n",
    "                    novelty_score += 0.3\n",
    "                else:\n",
    "                    novelty_score += 0.1\n",
    "                    \n",
    "        if novelty_score > 1.0:\n",
    "            novelty_score = 1.0\n",
    "            \n",
    "        return novelty_score\n",
    "    \n",
    "    # 评估论文的实质性内容\n",
    "    def evaluate_paper(self, text):\n",
    "        # 如果文本太短，直接判定为无实质内容\n",
    "        if len(text) < 2000:\n",
    "            return 1  \n",
    "            \n",
    "        # 提取论文的各个部分\n",
    "        paper_sections_title = self._extract_sections_title(text)\n",
    "        abstract = self._extract_abstract(text)\n",
    "        title = self._extract_title(text)\n",
    "        \n",
    "        metrics = {}\n",
    "        \n",
    "        # 计算各项指标\n",
    "        metrics['word_count'] = self._count_words(text)\n",
    "        metrics['lexical_diversity'] = self._calculate_lexical_diversity(text)\n",
    "        metrics['technical_term_density'] = self._technical_term_density(text)\n",
    "        metrics['citation_density'] = self._citation_density(text)\n",
    "        metrics['structure_completeness'] = self._check_structure(paper_sections_title)\n",
    "        metrics['argument_consistency'] = self._evaluate_argument_consistency(text, abstract)\n",
    "        metrics['novelty_score'] = self._assess_novelty(text, title)\n",
    "        \n",
    "        # 计算加权总分\n",
    "        weights = {\n",
    "            'word_count': 0.1,                 # 论文长度\n",
    "            'lexical_diversity': 0.1,          # 词汇多样性\n",
    "            'technical_term_density': 0.15,    # 术语使用\n",
    "            'citation_density': 0.1,           # 引用情况\n",
    "            'structure_completeness': 0.2,     # 结构完整性\n",
    "            'argument_consistency': 0.26,      # 论点一致性\n",
    "            'novelty_score': 0.08,             # 创新性\n",
    "        }\n",
    "        \n",
    "        # 确保所有指标都有值\n",
    "        for key in weights:\n",
    "            if key not in metrics:\n",
    "                metrics[key] = 0\n",
    "        \n",
    "        # 计算总分\n",
    "        weighted_score = 0\n",
    "        for key in weights:\n",
    "            weighted_score += weights[key] * metrics[key]\n",
    "        \n",
    "        # 长度惩罚: 如果论文太短，降低得分\n",
    "        if metrics['word_count'] < 2500:\n",
    "            length_penalty = metrics['word_count'] / 2500\n",
    "            weighted_score = weighted_score * length_penalty\n",
    "        \n",
    "        # 结构惩罚: 如果缺少核心章节，降低得分\n",
    "        if metrics['structure_completeness'] < 0.5:\n",
    "            structure_factor = 0.6 + 0.4 * metrics['structure_completeness']\n",
    "            weighted_score = weighted_score * structure_factor\n",
    "        return weighted_score\n",
    "\n",
    "# 论文处理\n",
    "class PaperProcessor:\n",
    "    def __init__(self, data_dir='./data'):\n",
    "        \"\"\"初始化论文处理器\"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        logger.info(\"加载BERT模型...\")\n",
    "        model_path = './model/bert-base-chinese'\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "        self.model = BertModel.from_pretrained(model_path)\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # 初始化评估器\n",
    "        self.evaluator = PaperEvaluator()\n",
    "\n",
    "    # 加载数据\n",
    "    def load_data(self):\n",
    "        try:\n",
    "            # 加载队伍信息\n",
    "            self.team_info = pd.read_excel(os.path.join(self.data_dir, '附件1.xlsx'))\n",
    "            \n",
    "            # 获取PDF文件列表\n",
    "            self.pdf_files = os.listdir(os.path.join(self.data_dir, 'transform/'))\n",
    "            \n",
    "            # 加载赛题内容\n",
    "            topic_path = os.path.join(self.data_dir, '附件2/topic.txt')\n",
    "            with open(topic_path, 'r', encoding='utf-8') as f:\n",
    "                self.topic_text = f.read()\n",
    "            \n",
    "            # 计算赛题的BERT嵌入\n",
    "            self.topic_embedding = self.get_bert_embedding(self.topic_text)\n",
    "            \n",
    "            logger.info(\"数据加载完成\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"数据加载失败: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    # 获取BERT嵌入向量\n",
    "    def get_bert_embedding(self, text):\n",
    "        try:\n",
    "            # 对文本进行编码\n",
    "            encoded = self.tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "            for key in encoded:\n",
    "                encoded[key] = encoded[key].to(self.device)\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**encoded)\n",
    "            \n",
    "            # 计算嵌入向量\n",
    "            embedding = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "            return embedding\n",
    "        except Exception as e:\n",
    "            logger.error(f\"获取BERT嵌入失败: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    # 计算文本与赛题的相似度\n",
    "    def calculate_similarity(self, text):\n",
    "        try:\n",
    "            # TF-IDF\n",
    "            vectorizer = TfidfVectorizer()\n",
    "            tfidf_matrix = vectorizer.fit_transform([text, self.topic_text])\n",
    "            tfidf_similarity = cosine_similarity(tfidf_matrix)[0][1]\n",
    "            \n",
    "            # BERT\n",
    "            text_embedding = self.get_bert_embedding(text)\n",
    "            if text_embedding is not None and self.topic_embedding is not None:\n",
    "                bert_similarity = cosine_similarity(text_embedding, self.topic_embedding)[0][0]\n",
    "            else:\n",
    "                bert_similarity = 0\n",
    "            \n",
    "            return {\n",
    "                'TF-IDF': tfidf_similarity,\n",
    "                'BERT': bert_similarity\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"计算相似度失败: {str(e)}\")\n",
    "            return {'TF-IDF': 0, 'BERT': 0}\n",
    "    \n",
    "    # 处理所有论文并生成结果\n",
    "    def process_papers(self):\n",
    "        if not self.load_data():\n",
    "            return False\n",
    "        \n",
    "        substance_scores = []  # 存储所有论文的实质性内容得分\n",
    "        paper_info = []  # 存储论文信息和初步结果\n",
    "        \n",
    "        # 处理每个队伍的论文\n",
    "        for idx, row in self.team_info.iterrows():\n",
    "            try:\n",
    "                # 初始化结果 [参赛队号, 是否包含参赛队信息, 是否与赛题无关, 原始实质性内容得分]\n",
    "                paper_result = [row['参赛队号'], 0, 1, 1] \n",
    "                \n",
    "                # 检查加密号是否在文件列表中\n",
    "                if row['加密号'] in self.pdf_files:\n",
    "                    # 构建论文路径\n",
    "                    paper_path = os.path.join(\n",
    "                        self.data_dir, f\"transform/{row['加密号']}/md/{row['加密号']}.md\"\n",
    "                    )\n",
    "                    if not os.path.exists(paper_path):\n",
    "                        logger.warning(f\"论文文件不存在: {paper_path}\")\n",
    "                        substance_scores.append(1)  # 文件不存在时得分为0\n",
    "                    else:\n",
    "                        with open(paper_path, 'r', encoding='utf-8') as f:\n",
    "                            text = f.read()\n",
    "                        \n",
    "                        # 1、检查参赛队信息是否包含在论文中\n",
    "                        for info in row[:-1]: \n",
    "                            if str(info) in text:\n",
    "                                paper_result[1] = 1\n",
    "                                break\n",
    "                        \n",
    "                        # 2、检查是否与赛题无关\n",
    "                        similarity = self.calculate_similarity(text)\n",
    "                        threshold = 0.35\n",
    "                        avg_similarity = (similarity['TF-IDF'] + similarity['BERT']) / 2\n",
    "                        if (similarity['TF-IDF'] > threshold or \n",
    "                            similarity['BERT'] > threshold or \n",
    "                            avg_similarity > threshold):\n",
    "                            paper_result[2] = 0\n",
    "\n",
    "                        # 3、获取实质性内容原始得分\n",
    "                        raw_score = self.evaluator.evaluate_paper(text)\n",
    "                        paper_result[3] = raw_score\n",
    "                        substance_scores.append(raw_score)\n",
    "                else:\n",
    "                    substance_scores.append(1)  # 文件不在列表中时得分为0\n",
    "                    \n",
    "                paper_info.append(paper_result)\n",
    "                logger.info(f\"处理完成: 参赛队号 {row['参赛队号']}, 初步结果: {paper_result}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.error(f\"处理论文出错 (参赛队号: {row['参赛队号']}): {str(e)}\")\n",
    "                paper_info.append([row['参赛队号'], -1, -1, 0])\n",
    "                substance_scores.append(0) \n",
    "        try:\n",
    "            substance_scores_array = np.array(substance_scores)\n",
    "            if len(substance_scores_array) > 1:\n",
    "                mask = substance_scores_array != 1\n",
    "                selected = substance_scores_array[mask]\n",
    "                if selected.size > 0:\n",
    "                    scaler = MinMaxScaler()\n",
    "                    normalized_selected = scaler.fit_transform(selected.reshape(-1, 1)).flatten()\n",
    "                    substance_scores_array[mask] = normalized_selected\n",
    "                normalized_scores = substance_scores_array.tolist()\n",
    "            else:\n",
    "                normalized_scores = substance_scores.copy()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"归一化处理失败: {str(e)}\")\n",
    "            normalized_scores = substance_scores\n",
    "        \n",
    "        print(\"归一化后的实质性内容得分:\", normalized_scores)\n",
    "\n",
    "        final_results = []\n",
    "        for i, paper in enumerate(paper_info):\n",
    "            final_substance_value = 0 if normalized_scores[i] >= 0.08 and normalized_scores[i] != 1 else 1\n",
    "            final_results.append([\n",
    "                paper[0], \n",
    "                paper[1],  \n",
    "                paper[2], \n",
    "                final_substance_value  # 最终实质内容判断结果\n",
    "            ])\n",
    "\n",
    "        result_df = pd.DataFrame(final_results, columns=[\n",
    "            '参赛队号', '是否包含参赛队信息', '是否与赛题无关', '是否无实质内容'\n",
    "        ])\n",
    "        try:\n",
    "            result_df.to_excel(os.path.join(self.data_dir, 'result2.xlsx'), sheet_name=\"Sheet1\", index=False)\n",
    "            logger.info(\"结果已保存\")\n",
    "            \n",
    "            # 筛选出问题论文\n",
    "            filtered = result_df[\n",
    "                (result_df['是否包含参赛队信息'] == 1) | \n",
    "                (result_df['是否与赛题无关'] == 1) | \n",
    "                (result_df['是否无实质内容'] == 1)\n",
    "            ]\n",
    "            filtered = filtered.sort_values('参赛队号')\n",
    "            top5 = filtered.head(5)  # 显示前5篇\n",
    "            return top5\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"保存结果失败: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        processor = PaperProcessor()\n",
    "        # 处理所有论文\n",
    "        top5_results = processor.process_papers()\n",
    "        if top5_results is not None:\n",
    "            logger.info(\"处理完成，以下是符合筛选条件的前5篇论文:\")\n",
    "            print(top5_results)\n",
    "        else:\n",
    "            logger.error(\"处理失败\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"主程序执行失败: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6368df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
